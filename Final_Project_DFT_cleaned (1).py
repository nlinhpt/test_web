import streamlit as st
import matplotlib.pyplot as plt
#!/usr/bin/env python
# coding: utf-8

# # üéß Noise Reduction with Discrete Fourier Transform

# ## üìå Introduction
# Trong k·ª∑ nguy√™n s·ªë, t√≠n hi·ªáu √¢m thanh v√† d·ªØ li·ªáu th∆∞·ªùng xuy√™n b·ªã "nhi·ªÖm b·∫©n" b·ªüi ti·∫øng ·ªìn kh√¥ng mong mu·ªën, l√†m gi·∫£m ƒë√°ng k·ªÉ ch·∫•t l∆∞·ª£ng v√† th√¥ng tin. Nh·∫±m kh√¥i ph·ª•c s·ª± trong tr·∫ªo c·ªßa d·ªØ li·ªáu, ƒë·ªÅ t√†i n√†y t·∫≠p trung kh√°m ph√° v√† ·ª©ng d·ª•ng Ph∆∞∆°ng ph√°p Fourier R·ªùi r·∫°c (Discrete Fourier Transform - DFT). DFT kh√¥ng ch·ªâ l√† m·ªôt c√¥ng c·ª• to√°n h·ªçc, m√† c√≤n l√† "c·∫∑p k√≠nh th·∫ßn k·ª≥" cho ph√©p ch√∫ng ta ph√¢n t√≠ch t√≠n hi·ªáu t·ª´ mi·ªÅn th·ªùi gian sang mi·ªÅn t·∫ßn s·ªë, n∆°i ti·∫øng ·ªìn th∆∞·ªùng b·ªôc l·ªô b·∫£n ch·∫•t v√† t·∫ßn s·ªë ƒë·∫∑c tr∆∞ng c·ªßa n√≥. B·∫±ng c√°ch ƒë·ªãnh v·ªã v√† lo·∫°i b·ªè c√°c th√†nh ph·∫ßn nhi·ªÖu ·ªü mi·ªÅn t·∫ßn s·ªë, ch√∫ng ta c√≥ th·ªÉ t√°ch bi·ªát ti·∫øng ·ªìn kh·ªèi t√≠n hi·ªáu mong mu·ªën m·ªôt c√°ch hi·ªáu qu·∫£ v√† tinh t·∫ø. B√°o c√°o n√†y s·∫Ω tr√¨nh b√†y chi ti·∫øt c√°ch tri·ªÉn khai v√† ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa DFT trong vi·ªác kh·ª≠ nhi·ªÖu t√≠n hi·ªáu, h∆∞·ªõng t·ªõi m·ªôt t∆∞∆°ng lai d·ªØ li·ªáu r√µ r√†ng v√† ch√≠nh x√°c h∆°n.
# 
# 

# ## üßÆ Mathematical Background

# 

# ## üéØ DFT and IDFT Implementation

# ### DFT and IDFT from scratch

# **Thu·∫≠t to√°n: Discrete Fourier Transform (DFT)**
# 
# **Input:** D√£y t√≠n hi·ªáu ƒë·∫ßu v√†o $x \in \mathbb{R}^n$
# 
# **Output:** D√£y ph·ªï t·∫ßn s·ªë $X\in \mathbb{C}^n$
# 
# 1. Chuy·ªÉn $x$ th√†nh m·∫£ng s·ªë th·ª±c (n·∫øu ch∆∞a)
# 2. G√°n $n \leftarrow \text{ƒë·ªô d√†i c·ªßa } x$
# 3. Kh·ªüi t·∫°o ma tr·∫≠n Fourier $F \in \mathbb{C}^{n \times n}$
# 4. V·ªõi m·ªói $j = 0$ ƒë·∫øn $n - 1$:
#    - V·ªõi m·ªói $k = 0$ ƒë·∫øn $n - 1$:
#      - $F[j][k] = e^{-2\pi i \cdot jk / n}$
# 5. T√≠nh t√≠ch: $X = F \cdot x$
# 6. Tr·∫£ v·ªÅ $X$
# 

# **Thu·∫≠t to√°n: Inverse Discrete Fourier Transform (IDFT)**
# 
# **Input:** D√£y ph·ªï t·∫ßn s·ªë ƒë·∫ßu v√†o $X \in \mathbb{C}^n$
# 
# **Output:** D√£y t√≠n hi·ªáu kh√¥i ph·ª•c $x \in \mathbb{C}^n$
# 
# 1. Chuy·ªÉn $X$ th√†nh m·∫£ng s·ªë ph·ª©c
# 2. G√°n $n \leftarrow \text{ƒë·ªô d√†i c·ªßa } X $
# 3. Kh·ªüi t·∫°o ma tr·∫≠n Fourier ng∆∞·ª£c $F_{\text{inv}} \in \mathbb{C}^{n \times n}$
# 4. V·ªõi m·ªói $j = 0$ ƒë·∫øn $n - 1$:
#    - V·ªõi m·ªói $k = 0$ ƒë·∫øn $n - 1$:
#      - $F_{\text{inv}}[j][k] = e^{+2\pi i \cdot jk / n}$
# 5. T√≠nh t√≠ch: $x = F_{\text{inv}} \cdot X$
# 6. Chu·∫©n h√≥a: $x \leftarrow \frac{x}{n}$
# 7. Tr·∫£ v·ªÅ $x$
# 

# In[3]:


#get_ipython().system('pip install pydub')


# In[4]:


#get_ipython().system('pip install soundfile')


# In[5]:


import numpy as np
import matplotlib.pyplot as plt
from IPython.display import Audio, display
from pydub import AudioSegment
import numpy as np
import plotly.graph_objects as go
import numpy as np
import soundfile as sf
from scipy.io.wavfile import write
from tqdm import tqdm  # Import tqdm for progress bar
from scipy.signal import butter, filtfilt, fftconvolve


# In[6]:


def dft(x):
    """
    Discrete Fourier Transform (DFT) using Fourier Matrix.
    x: array-like, shape (n,)
    return: array of complex numbers, shape (n,)
    """
    x = np.asarray(x, dtype=float)  # chuy·ªÉn v·ªÅ d·∫°ng float
    n = x.shape[0]  # l·∫•y s·ªë l∆∞·ª£ng sample

    # T·∫°o ma tr·∫≠n Fourier F
    F = np.zeros((n, n), dtype=complex)
    for j in range(n):  # Duy·ªát qua c√°c d√≤ng (ch·ªâ s·ªë th·ªùi gian)
        for k in range(n):  # Duy·ªát qua c√°c c·ªôt (ch·ªâ s·ªë t·∫ßn s·ªë)
            F[j][k] = np.exp(-2j * np.pi * j * k / n)  # T√≠nh ph·∫ßn t·ª≠ F[j][k]

    # T√≠nh X: F[n x n] @ x [n x 1] = X [n x 1]
    X = F @ x

    return X

def idft(X):
    """
    Inverse Discrete Fourier Transform (IDFT) from scratch.
    X: array-like, shape (n,)
    return: array of complex numbers, shape (n,)
    """
    X = np.asarray(X, dtype=complex)  # ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë·∫ßu v√†o l√† s·ªë ph·ª©c
    n = X.shape[0]  # l·∫•y s·ªë l∆∞·ª£ng sample

    # T·∫°o ma tr·∫≠n Inverse Fourier F
    F_inv = np.zeros((n, n), dtype=complex)
    for j in range(n):  # Duy·ªát qua c√°c d√≤ng (ch·ªâ s·ªë th·ªùi gian)
        for k in range(n):  # Duy·ªát qua c√°c c·ªôt (ch·ªâ s·ªë t·∫ßn s·ªë)
            F_inv[j][k] = np.exp(2j * np.pi * j * k / n)  # T√≠nh ph·∫ßn t·ª≠ F[j][k]

    # T√≠nh X: F_inv [n x n] @ X [n x 1] = x [n x 1]
    x = F_inv @ X

    return x / n


# ### üîä Audio Signal Example

# #### üß™ Example 5.8.3

# 
# ### B√†i to√°n
# 
# Gi·∫£ s·ª≠ ta ƒë·∫∑t m·ªôt microphone d∆∞·ªõi m·ªôt chi·∫øc tr·ª±c thƒÉng ƒëang l∆° l·ª´ng, trong v√≤ng 1 gi√¢y micro ghi l·∫°i t√≠n hi·ªáu √¢m thanh nh∆∞ bi·ªÉu ƒë·ªì h√¨nh 5.8.3. T√≠n hi·ªáu c√≥ nhi·ªÅu dao ƒë·ªông, nh∆∞ng do nhi·ªÖu n√™n kh√¥ng r√µ r√†ng.
# 
# **M·ª•c ti√™u:** D√πng DFT ƒë·ªÉ ph√¢n t√≠ch t√≠n hi·ªáu v√† t√¨m ra nh·ªØng t·∫ßn s·ªë ch√≠nh.
# 
# 
# ### M√¥ h√¨nh t√≠n hi·ªáu v√† gi·∫£ ƒë·ªãnh
# 
# Ta gi·∫£ ƒë·ªãnh t√≠n hi·ªáu thu ƒë∆∞·ª£c c√≥ d·∫°ng:
# 
# $y(\tau) = \cos(2\pi \cdot 80 \tau) + 2 \sin(2\pi \cdot 50 \tau) + \text{Noise}$
# 
# - Dao ƒë·ªông th·∫≠t: Cos 80Hz v√† sin 50Hz
# - Noise: ng·∫´u nhi√™n, che khu·∫•t dao ƒë·ªông ch√≠nh
# - L·∫•y m·∫´u 512 ƒëi·ªÉm: $t = 0, \frac{1}{512}, \frac{2}{512}, ..., \frac{511}{512}$
# 
# 
# ### Th·ª±c hi·ªán bi·∫øn ƒë·ªïi Fourier r·ªùi r·∫°c
# 
# - G·ªçi $x \in \mathbb{R}^{512}$ l√† vector t√≠n hi·ªáu thu ƒë∆∞·ª£c.
# - T√≠nh DFT:
#   $y = \frac{2}{n} F_n x = a + ib$
#   Trong ƒë√≥:
#   - $a = \text{Re}(y)$: bi·ªÉu di·ªÖn ph·∫ßn cos
#   - $b = \text{Im}(y)$: bi·ªÉu di·ªÖn ph·∫ßn sin
# - Ch·ªâ x√©t n·ª≠a ƒë·∫ßu ph·ªï (0 ‚Üí 255) do t√≠nh ƒë·ªëi x·ª©ng.
# 

# In[7]:


# 1. Sinh d·ªØ li·ªáu t√≠n hi·ªáu m·∫´u
n = 512           # s·ªë m·∫´u
T = 1.0           # th·ªùi l∆∞·ª£ng (gi√¢y)
t = np.linspace(0, T, n, endpoint=False)
f1 = 80           # t·∫ßn s·ªë 1 (Hz)
f2 = 50           # t·∫ßn s·ªë 2 (Hz)

np.random.seed(42)
noise = np.random.normal(0, 1, n)
y = np.cos(2 * np.pi * f1 * t) + 2 * np.sin(2 * np.pi * f2 * t) + noise


# In[8]:


# Time domain
plt.figure(figsize=(10,3))
plt.plot(t, y)
plt.title('Composite Signal')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
st.pyplot(plt.gcf())


# In[9]:


Y = dft(y)
freq = np.fft.fftfreq(n, d=t[1] - t[0])

plt.figure(figsize=(10,6))
plt.subplot(2, 1, 1)
plt.stem(freq[:n//2], np.real(Y[:n//2]), basefmt=" ")
plt.title('Frequency Spectrum - Real Part')
plt.ylabel('Amplitude (Real)')

plt.subplot(2, 1, 2)
plt.stem(freq[:n//2], np.imag(Y[:n//2]), basefmt=" ")
plt.title('Frequency Spectrum - Imaginary Part')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Amplitude (Imag)')
plt.tight_layout()
st.pyplot(plt.gcf())


# In[10]:


y_rec = idft(Y) # Chuy·ªÉn t·ª´ frequency domain -> time domain

plt.figure(figsize=(10,3))
plt.plot(t, y.real, label='Original Signal')
plt.plot(t, y_rec.real, '--', label='Reconstructed from IDFT')
plt.title("Comparison of Original Signal and Reconstructed Signal from IDFT")
plt.xlabel('Time (s)')
plt.legend()
st.pyplot(plt.gcf())


# 
# ### Nh·∫≠n x√©t k·∫øt qu·∫£
# 
# - Ph·ªï ph·∫ßn th·ª±c (a): spike t·∫°i index 80 $\Rightarrow \cos(2\pi \cdot 80\tau)$
# - Ph·ªï ph·∫ßn ·∫£o (b): spike t·∫°i index 50 $\Rightarrow \sin(2\pi \cdot 50\tau)$
# 
# $\Rightarrow \text{T√≠n hi·ªáu ban ƒë·∫ßu ƒë√∫ng l√†: } y(\tau) = \cos(2\pi 80\tau) + 2 \sin(2\pi 50\tau) + \text{Noise}$
# 
# 
# ### K·∫øt lu·∫≠n
# 
# - DFT gi√∫p t√°ch t·∫ßn s·ªë ch√≠nh kh·ªèi nhi·ªÖu ng·∫´u nhi√™n.
# - Bi·ªÉu ƒë·ªì ph·ªï t·∫ßn s·ªë cho th·∫•y r√µ nh·ªØng th√¥ng tin kh√¥ng nh√¨n ƒë∆∞·ª£c trong th·ªùi gian.
# - C√°ch d√πng DFT: $x \rightarrow F_n x \rightarrow \text{Tr√≠ch xu·∫•t dao ƒë·ªông}$
# - Bi·∫øn ƒë·ªïi DFT gi√∫p chuy·ªÉn t√≠n hi·ªáu t·ª´ th·ªùi gian sang t·∫ßn s·ªë.
# - N·∫øu bi·∫øt DFT, ta c√≥ th·ªÉ ‚Äúnh√¨n th·∫•y‚Äù nh·ªØng dao ƒë·ªông ƒëang b·ªã nhi·ªÖu che l·∫•p.
# 

# ### üîä Real-world Noise Reduction with DFT

# #### Load and Visualize Audio Signal

# **C√°c h√†m c·∫ßn thi·∫øt**

# In[11]:


# Class v·∫Ω file √¢m thanh theo 2 mi·ªÅn (Time Domain - Frequency Domain)
class SignalAnalyzer:
    def __init__(self, signal, sr):
        self.signal = signal
        self.sr = sr
        self.n = len(signal)
        self.time_axis = np.linspace(0, self.n / sr, self.n, endpoint=False)
        self.fft_result = np.fft.fft(signal)
        self.frequencies = np.fft.fftfreq(self.n, d=1/sr)

    def amplitude(self):
        return np.abs(self.fft_result)

    def plot_spectrum(self, interactive=False):
        if interactive:
            trace = go.Scatter(x=self.frequencies[:self.n//2],
                               y=self.amplitude()[:self.n//2],
                               mode='lines')
            layout = go.Layout(title='Spectrum',
                               xaxis=dict(title='Frequency [Hz]'),
                               yaxis=dict(title='Amplitude'))
            fig = go.Figure(data=[trace], layout=layout)
            fig.show()
        else:
            plt.figure(figsize=(10,6))
            plt.plot(self.frequencies[:self.n//2], self.amplitude()[:self.n//2])
            plt.title('Spectrum')
            plt.ylabel('Amplitude')
            plt.xlabel('Frequency [Hz]')
            plt.grid(True)
            st.pyplot(plt.gcf())

    def plot_time_frequency(self, t_ylabel="Amplitude", f_ylabel="Amplitude",
                            t_title="Signal (Time Domain)",
                            f_title="Spectrum (Frequency Domain)"):
        # Time domain
        trace_time = go.Scatter(x=self.time_axis, y=self.signal, mode='lines')
        layout_time = go.Layout(title=t_title,
                                xaxis=dict(title='Time [sec]'),
                                yaxis=dict(title=t_ylabel),
                                width=1000, height=400)
        fig_time = go.Figure(data=[trace_time], layout=layout_time)
        fig_time.show()

        # Frequency domain
        trace_freq = go.Scatter(x=self.frequencies[:self.n//2],
                                y=self.amplitude()[:self.n//2],
                                mode='lines')
        layout_freq = go.Layout(title=f_title,
                                xaxis=dict(title='Frequency [Hz]'),
                                yaxis=dict(title=f_ylabel),
                                width=1000, height=400)
        fig_freq = go.Figure(data=[trace_freq], layout=layout_freq)
        fig_freq.show()


#Top frequencies
def analyze_frequency(input_file, start_time, end_time, sr):
    """
    Analyze the frequency components of a signal in a specific time range.

    Parameters:
        input_file (str): Path to the input audio file (.wav).
        start_time (float): Start time in seconds for analysis.
        end_time (float): End time in seconds for analysis.
        sr (int): Sampling rate of the audio file (Hz).

    Returns:
        freq_peaks (list): List of frequencies with the highest amplitudes.
    """
    # Step 1: Load the audio file
    y_real, sr = sf.read(input_file)
    if len(y_real.shape) > 1:  # Convert to mono if stereo
        y_real = np.mean(y_real, axis=1)

    # Step 2: Define the sample range for the desired time window
    start_sample = int(start_time * sr)
    end_sample = int(end_time * sr)
    signal_segment = y_real[start_sample:end_sample]

    # Step 3: Apply FFT to the segment
    n = len(signal_segment)
    signal_fft = np.fft.fft(signal_segment)
    freqs = np.fft.fftfreq(n, d=1/sr)
    magnitude = np.abs(signal_fft)

    # Step 4: Filter positive frequencies only
    pos_freqs = freqs[:n // 2]
    pos_magnitude = magnitude[:n // 2]

    # Step 5: Find the peaks in the frequency domain
    peak_indices = np.argsort(pos_magnitude)[-5:]  # Get the top 5 frequencies
    freq_peaks = pos_freqs[peak_indices]

    # Step 6: Plot the spectrum
    plt.figure(figsize=(10, 6))
    plt.plot(pos_freqs, pos_magnitude)
    plt.title("Spectrum (Frequency Domain)")
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("Amplitude")
    plt.axvline(x=freq_peaks[0], color='r', linestyle='--', label=f"Peak: {freq_peaks[0]:.2f} Hz")
    plt.legend()
    plt.grid()
    st.pyplot(plt.gcf())

    print(f"Top frequencies in the range {start_time}-{end_time} seconds:", freq_peaks)
    return freq_peaks



# **Load file**

# In[12]:


file_path = "D:/Download/noisy_sound.mp3"


# In[13]:


audio = AudioSegment.from_file(file_path)
if audio.channels > 1:
    audio = audio.set_channels(1)
#----------------------------------------------------------------------#
signal_vector = np.array(audio.get_array_of_samples(), dtype=np.float64)
frame_rate = audio.frame_rate
sample_width = audio.sample_width
channels = audio.channels
display(Audio(signal_vector, rate=frame_rate))
print(f"T√≠n hi·ªáu ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi k√≠ch th∆∞·ªõc: {signal_vector.shape[0]}")
print(f"T·ªëc ƒë·ªô khung h√¨nh (frame rate): {frame_rate} Hz")
print(f"ƒê·ªô r·ªông m·∫´u (sample width): {sample_width} bytes")
print(f"S·ªë k√™nh (channels): {channels}")


# **Time Domain vs. Frequency Domain**

# In[ ]:


analyzer = SignalAnalyzer(signal_vector, frame_rate)
analyzer.plot_time_frequency()        # V·∫Ω t∆∞∆°ng t√°c c·∫£ 2 mi·ªÅn


# **X√°c ƒë·ªãnh c√°c mi·ªÅn t·∫ßn trong kho·∫£ng th·ªùi gian nh·∫•t ƒë·ªãnh**

# In[ ]:


start_time = 250  # Start time in seconds
end_time = 289  # End time in seconds
top_frequencies = analyze_frequency(file_path , start_time, end_time, frame_rate)


# **Ch·∫°y DFT**

# In[14]:


# Y = dft(signal_vector)


# > V√¨ d√πng dft th·ªß c√¥ng th√¨ b·ªô nh·ªõ kh√¥ng c·∫•p ph√°t n·ªïi ‚Üí c√°i fft gi√∫p gi·∫£m ƒë·ªô ph·ª©c t·∫°p xu·ªëng

# ### üö´ Common DFT Issues: Aliasing, Leakage, Resolution

# #### Aliasing

# In[ ]:





# #### Leakage

# In[ ]:





# #### Resolution

# In[ ]:





# ### ‚ö° From DFT to FFT

# V√¨ thu·∫≠t to√°n DFT truy·ªÅn th·ªëng ƒë√≤i h·ªèi l∆∞·ª£ng l·ªõn ph√©p t√≠nh v√† b·ªô nh·ªõ, ƒë·∫∑c bi·ªát v·ªõi t√≠n hi·ªáu d√†i, n√™n ng∆∞·ªùi ta ƒë√£ ph√°t tri·ªÉn ph∆∞∆°ng ph√°p ph√¢n r√£ ma tr·∫≠n Fourier t·ª´ ƒë√≥ t·∫°o ra thu·∫≠t to√°n FFT, gi√∫p tƒÉng t·ªëc t√≠nh to√°n ƒë√°ng k·ªÉ.

# #### Decomposing the Fourier Matrix
# 
# Gi√∫p t√≠nh to√°n Fourier Transform nhanh h∆°n b·∫±ng c√°ch **ph√¢n r√£ ma tr·∫≠n Fourier l·ªõn** $\mathbf{F}_n$ th√†nh nh·ªØng ph·∫ßn nh·ªè h∆°n, c·ª• th·ªÉ l√† 2 ma tr·∫≠n Fourier c·∫•p $\frac{n}{2}$.  
# 
# N·∫øu $n = 2^r$, th√¨:
# $
# \mathbf{F}_n =
# \begin{pmatrix}
# \mathbf{F}_{n/2} & \mathbf{D}_{n/2} \mathbf{F}_{n/2} \\
# \mathbf{F}_{n/2} & -\mathbf{D}_{n/2} \mathbf{F}_{n/2}
# \end{pmatrix}
# \mathbf{P}_n
# $
# 
# Trong ƒë√≥:
# 
# - $\mathbf{F}_n$: Ma tr·∫≠n Fourier c·∫•p **n**.  
# - $\mathbf{F}_{n/2}$: Ma tr·∫≠n Fourier c·∫•p nh·ªè h∆°n, k√≠ch th∆∞·ªõc $\frac{n}{2}$.  
# - $\mathbf{D}_{n/2}$: Ma tr·∫≠n ƒë∆∞·ªùng ch√©o ch·ª©a c√°c cƒÉn b·∫≠c **n** c·ªßa 1.  
# - $\mathbf{P}_n$: Ma tr·∫≠n ho√°n v·ªã "even‚Äìodd" (ƒë·ªïi v·ªã tr√≠ ch·ªâ s·ªë ch·∫µn v√† l·∫ª).
# 
# 
# 
# **Ma tr·∫≠n $\mathbf{D}_{n/2}$:**
# 
# $\mathbf{D}_{n/2} = \mathrm{diag}(1, \xi, \xi^2, \dots, \xi^{n/2 - 1})$
# 
# - V·ªõi $\xi = e^{-2\pi i / n}$.  
# 
# 
# **Ma tr·∫≠n ho√°n v·ªã $\mathbf{P}_n$:**
# 
# $
# \mathbf{P}_n^T = [e_0, e_2, e_4, \dots, e_{n-2} \mid e_1, e_3, e_5, \dots, e_{n-1}]
# $
# 
# - Vector c∆° s·ªü ƒë∆∞·ª£c s·∫Øp x·∫øp l·∫°i:
#   - C√°c ch·ªâ s·ªë **ch·∫µn** ƒë·ª©ng tr∆∞·ªõc.
#   - C√°c ch·ªâ s·ªë **l·∫ª** ƒë·ª©ng sau.
# - T√°c d·ª•ng: t√°ch t√≠n hi·ªáu ƒë·∫ßu v√†o th√†nh **even** v√† **odd**, ph·ª•c v·ª• cho b∆∞·ªõc chia ƒë·ªÉ tr·ªã.
# 
# 

# #### Bi·∫øn ƒë·ªïi Fourier Nhanh (Fast Fourier Transform)
# 
# V·ªõi m·ªôt vector ƒë·∫ßu v√†o **x** c√≥ s·ªë ph·∫ßn t·ª≠ $n = 2^r$, bi·∫øn ƒë·ªïi Fourier r·ªùi r·∫°c $\mathbf{F}_n \mathbf{x}$ ƒë∆∞·ª£c t√≠nh b·∫±ng c√°ch l·∫ßn l∆∞·ª£t t·∫°o ra c√°c m·∫£ng sau:
# 
# $
# \mathbf{X}_{1 \times n} \leftarrow \text{rev}(\mathbf{x}) \quad \text{(ƒë·∫£o bit c√°c ch·ªâ s·ªë)}
# $
# 
# V·ªõi $j = 0, 1, 2, 3, \ldots, r - 1$:
# 
# $
# \mathbf{D} \leftarrow
# \begin{pmatrix}
# 1 \\
# e^{-\pi i / 2^j} \\
# e^{-2\pi i / 2^j} \\
# e^{-3\pi i / 2^j} \\
# \vdots \\
# e^{-(2^j - 1)\pi i / 2^j}
# \end{pmatrix}_{2^j \times 1}$
# M·ªôt n·ª≠a s·ªë cƒÉn b·∫≠c $2^{j+1}$ c·ªßa 1, c√≥ th·ªÉ l·∫•y t·ª´ b·∫£ng tra tr∆∞·ªõc
# 
# $
# \mathbf{X}^{(0)} = 
# \begin{pmatrix}
# \mathbf{X}_{*0} \quad \mathbf{X}_{*2} \quad \mathbf{X}_{*4} \quad \cdots \quad \mathbf{X}_{*2^{r - j} - 2}
# \end{pmatrix}_{2^j \times 2^{r - j - 1}}
# $
# 
# $
# \mathbf{X}^{(1)} = 
# \begin{pmatrix}
# \mathbf{X}_{*1} \quad \mathbf{X}_{*3} \quad \mathbf{X}_{*5} \quad \cdots \quad \mathbf{X}_{*2^{r - j} - 1}
# \end{pmatrix}_{2^j \times 2^{r - j - 1}}
# $
# 
# $
# \mathbf{X} \leftarrow
# \begin{pmatrix}
# \mathbf{X}^{(0)} + \mathbf{D} \times \mathbf{X}^{(1)} \\
# \mathbf{X}^{(0)} - \mathbf{D} \times \mathbf{X}^{(1)}
# \end{pmatrix}_{2^{j+1} \times 2^{r - j - 1}}
# $
# 
# > ƒê·ªãnh nghƒ©a ph√©p nh√¢n ph·∫ßn t·ª≠:  
# > $
# > [\mathbf{D} \times \mathbf{M}]_{ij} = d_i m_{ij}
# > $
# 
# 

# In[ ]:


def fft_from_scratch(x):
    """
    FFT ƒë·ªá quy thu·∫ßn l√Ω thuy·∫øt, theo ph√¢n r√£ ma tr·∫≠n Fourier:
    F_n = [[F_{n/2}, D*F_{n/2}],
           [F_{n/2}, -D*F_{n/2}]] * P_n
    """
    x = np.asarray(x, dtype=complex)
    n = x.shape[0]

    if n == 1:
        return x

    if n & (n - 1) != 0:
        raise ValueError("Input length must be a power of 2")

    # ƒê·ªá quy chia ƒë·ªÉ tr·ªã
    even = fft_from_scratch(x[::2])
    odd = fft_from_scratch(x[1::2])

    # Xoay pha
    twiddles = np.exp(-2j * np.pi * np.arange(n // 2) / n)

    # K·∫øt h·ª£p theo c√¥ng th·ª©c ph√¢n r√£
    top = even + twiddles * odd
    bottom = even - twiddles * odd

    return np.concatenate([top, bottom])


# #### **2. Bi·∫øn ƒë·ªïi Fourier Nhanh Ng∆∞·ª£c (IFFT) - D·ª±a tr√™n IDFT**

# 
# Gi·∫£ s·ª≠ $\mathbf{X}$ ƒë√£ ƒë∆∞·ª£c ƒë·∫£o bit th·ª© t·ª± (bit-reversal), th√¨ th·ª±c hi·ªán theo t·ª´ng m·ª©c $j = 0, 1, \dots, r-1$:
# 
# T·∫°o vector xoay pha (li√™n h·ª£p c·ªßa vector FFT):
# 
# $
# \mathbf{D} \leftarrow
# \begin{pmatrix}
# 1 \
# e^{+\pi i / 2^j} \
# e^{+2\pi i / 2^j} \
# e^{+3\pi i / 2^j} \
# \vdots \
# e^{+(2^j - 1)\pi i / 2^j}
# \end{pmatrix}_{2^j \times 1}
# $
# 
# T√°ch ma tr·∫≠n ƒë·∫ßu v√†o th√†nh 2 n·ª≠a:
# 
# $
# \mathbf{X}^{(0)} =
# \begin{pmatrix}
# \mathbf{X}{*0} \quad \mathbf{X}{*2} \quad \mathbf{X}{*4} \quad \cdots
# \end{pmatrix}
# \quad,\quad
# \mathbf{X}^{(1)} =
# \begin{pmatrix}
# \mathbf{X}{*1} \quad \mathbf{X}_{*3} \quad \cdots
# \end{pmatrix}
# $
# 
# C·∫≠p nh·∫≠t $\mathbf{X}$ ·ªü b∆∞·ªõc ti·∫øp theo:
# 
# $
# \mathbf{X} \leftarrow
# \begin{pmatrix}
# \mathbf{X}^{(0)} + \mathbf{D} \times \mathbf{X}^{(1)} \
# \mathbf{X}^{(0)} - \mathbf{D} \times \mathbf{X}^{(1)}
# \end{pmatrix}
# $
# 
# Sau c√πng, chia to√†n b·ªô $\mathbf{X}$ cho $n$ ƒë·ªÉ chu·∫©n h√≥a:
# 
# $
# \boxed{
# \mathbf{x} = \frac{1}{n} \cdot \mathbf{X}
# }
# $

# In[ ]:


# ifft d√πng idft
def ifft_from_definition(X):
    """
    IFFT t·ª´ ƒë·ªãnh nghƒ©a kh√¥ng d√πng FFT, kh√¥ng d√πng li√™n h·ª£p.
    """
    X = np.asarray(X, dtype=complex)
    n = X.shape[0]
    if n & (n - 1) != 0:
        raise ValueError("Input length must be a power of 2")

    F_inv = idft(n)
    x = F_inv @ X
    return x.real  # Ch·ªâ l·∫•y ph·∫ßn th·ª±c n·∫øu l√† t√≠n hi·ªáu √¢m thanh


# #### **3. Bi·∫øn ƒë·ªïi Fourier Nhanh Ng∆∞·ª£c (IFFT) - D·ª±a tr√™n FFT**

# IFFT (Inverse Fast Fourier Transform) l√† thu·∫≠t to√°n hi·ªáu qu·∫£ ƒë·ªÉ t√≠nh to√°n Bi·∫øn ƒë·ªïi Fourier R·ªùi r·∫°c Ng∆∞·ª£c (IDFT). Thay v√¨ tri·ªÉn khai m·ªôt thu·∫≠t to√°n IFFT ri√™ng bi·ªát t·ª´ ƒë·∫ßu, m·ªôt ph∆∞∆°ng ph√°p ph·ªï bi·∫øn v√† hi·ªáu qu·∫£ l√† t√°i s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n FFT (thu·∫≠n) ƒë√£ c√≥. Ph∆∞∆°ng ph√°p n√†y d·ª±a tr√™n m·ªôt t√≠nh ch·∫•t quan tr·ªçng c·ªßa DFT v√† IDFT.
# 
# M·ªëi quan h·ªá gi·ªØa DFT v√† IDFT c√≥ th·ªÉ ƒë∆∞·ª£c khai th√°c ƒë·ªÉ t√≠nh to√°n IDFT b·∫±ng c√°ch s·ª≠ d·ª•ng m·ªôt thu·∫≠t to√°n DFT (FFT) chu·∫©n. C√¥ng th·ª©c c·ªßa IDFT l√†:
# 
# $$x[n] = \frac{1}{N} \sum_{k=0}^{N-1} X[k]e^{+j\frac{2\pi}{N}nk}$$
# 
# C√¥ng th·ª©c c·ªßa DFT l√†:
# 
# $$Y[k] = \sum_{n=0}^{N-1} y[n]e^{-j\frac{2\pi}{N}nk}$$
# 
# N·∫øu ch√∫ng ta so s√°nh hai c√¥ng th·ª©c n√†y, ta c√≥ th·ªÉ th·∫•y m·ªôt m·ªëi li√™n h·ªá th√¥ng qua to√°n t·ª≠ li√™n h·ª£p ph·ª©c (conjugate).
# C·ª• th·ªÉ, n·∫øu ch√∫ng ta t√≠nh DFT c·ªßa li√™n h·ª£p ph·ª©c c·ªßa $X[k]$ (t·ª©c l√† $\bar{X}[k]$):
# 
# $$DFT(\bar{X}[k]) = \sum_{k=0}^{N-1} \bar{X}[k]e^{-j\frac{2\pi}{N}nk}$$
# 
# B·∫±ng c√°ch s·ª≠ d·ª•ng t√≠nh ch·∫•t $\overline{(AB)} = \bar{A}\bar{B}$ v√† $\overline{(e^{j\theta})} = e^{-j\theta}$, ta c√≥:
# 
# $$DFT(\bar{X}[k]) = \overline{\left( \sum_{k=0}^{N-1} X[k]e^{+j\frac{2\pi}{N}nk} \right)}$$
# 
# Nh·∫≠n th·∫•y r·∫±ng t·ªïng trong ngo·∫∑c ƒë∆°n ch√≠nh l√† $N \cdot x[n]$ t·ª´ c√¥ng th·ª©c IDFT:
# 
# $$DFT(\bar{X}[k]) = \overline{(N \cdot x[n] )} = N \cdot \bar{x}[n]$$
# 
# T·ª´ ƒë√≥, suy ra:
# $$\bar{x}[n] = \frac{1}{N} DFT(\bar{X}[k])$$
# 
# V√† ƒë·ªÉ t√¨m $x[n]$, ch√∫ng ta ch·ªâ c·∫ßn l·∫•y li√™n h·ª£p ph·ª©c c·ªßa k·∫øt qu·∫£ n√†y:
# 
# $$x[n] = \overline{\left( \frac{1}{N} DFT(\bar{X}[k]) \right)} = \frac{1}{N} \overline{DFT(\bar{X}[k])}$$

# In[ ]:


def ifft_from_scratch(X):
    """
    IFFT ƒë·ªá quy theo ƒë·ªãnh nghƒ©a:
    ifft(x) = conj(fft(conj(x))) / n
    """
    X = np.asarray(X, dtype=complex)
    n = X.shape[0]

    if n & (n - 1) != 0:
        raise ValueError("Input length must be a power of 2")

    x = fft_from_scratch(np.conjugate(X))
    x = np.conjugate(x) / n # conjugate() t√≠nh li√™n h·ª£p ph·ª©c

    return x.real


# In[ ]:





# #### üî¨ Convolution trong FFT

# 
# Cho  $\mathbf{a} \times \mathbf{b}$ l√† ph√©p **nh√¢n t·ª´ng ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng**, ta c√≥:
# 
# $\mathbf{a} \times \mathbf{b} =
# \begin{pmatrix}
# \alpha_0 \\
# \alpha_1 \\
# \vdots \\
# \alpha_{n-1}
# \end{pmatrix} \times \begin{pmatrix}
# \beta_0 \\
# \beta_1 \\
# \vdots \\
# \beta_{n-1}
# \end{pmatrix}
# =$
# $
# \begin{pmatrix}
# \alpha_0 \beta_0 \\
# \alpha_1 \beta_1 \\
# \vdots \\
# \alpha_{n-1} \beta_{n-1}
# \end{pmatrix}_{n \times 1}$
# 
# 
# 
# Gi·∫£ s·ª≠ $\hat{\mathbf{a}}$ v√† $\hat{\mathbf{b}}$ l√† **c√°c vector ƒë∆∞·ª£c padding th√™m 0** ƒë·ªÉ c√≥ ƒë·ªô d√†i g·∫•p ƒë√¥i:
# 
# $
# \hat{\mathbf{a}} =
# \begin{pmatrix}
# \alpha_0 \\
# \vdots \\
# \alpha_{n-1} \\
# 0 \\
# \vdots \\
# 0
# \end{pmatrix}_{2n \times 1}
# \quad \text{v√†} \quad
# \hat{\mathbf{b}} =
# \begin{pmatrix}
# \beta_0 \\
# \vdots \\
# \beta_{n-1} \\
# 0 \\
# \vdots \\
# 0
# \end{pmatrix}_{2n \times 1}
# $
# 
# N·∫øu $\mathbf{F} = \mathbf{F}_{2n}$ l√† **ma tr·∫≠n Fourier r·ªùi r·∫°c c·∫•p $2n$** (√°p d·ª•ng trong FFT), th√¨:
# $
# \mathbf{F}(\mathbf{a} * \mathbf{b}) = (\mathbf{F} \hat{\mathbf{a}}) \times (\mathbf{F} \hat{\mathbf{b}})
# $ 
# v√†:
# $
# \boxed{
# \mathbf{a} * \mathbf{b} = \mathbf{F}^{-1} \left[ (\mathbf{F} \hat{\mathbf{a}}) \times (\mathbf{F} \hat{\mathbf{b}}) \right]
# }
# \quad \text{(5.8.12)}
# $
# 
# 
# 
# > **T√≠ch ch·∫≠p tuy·∫øn t√≠nh trong mi·ªÅn th·ªùi gian** c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán hi·ªáu qu·∫£ h∆°n b·∫±ng c√°ch **chuy·ªÉn sang mi·ªÅn t·∫ßn s·ªë**, nh·ªù ƒë·ªãnh l√Ω t√≠ch ch·∫≠p.
# 
# Thay v√¨ t√≠nh tr·ª±c ti·∫øp t√≠ch ch·∫≠p (r·∫•t t·ªën th·ªùi gian), ta l√†m nh∆∞ sau:
# 
# 1. **Ch√®n th√™m s·ªë 0 (padding)** v√†o t√≠n hi·ªáu v√† b·ªô l·ªçc ƒë·ªÉ tr√°nh hi·ªán t∆∞·ª£ng wrap-around.
# 2. **D√πng FFT** ƒë·ªÉ bi·∫øn ƒë·ªïi c·∫£ hai sang mi·ªÅn t·∫ßn s·ªë:  
#    $$
#    X = \text{FFT}(x), \quad H = \text{FFT}(h)
#    $$
# 3. **Nh√¢n t·ª´ng ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng trong mi·ªÅn t·∫ßn s·ªë**:  
#    $$
#    Y = X \cdot H
#    $$
# 4. **D√πng IFFT** ƒë·ªÉ ƒë∆∞a k·∫øt qu·∫£ tr·ªü l·∫°i mi·ªÅn th·ªùi gian:  
#    $$
#    y = \text{IFFT}(Y)
#    $$
# 
# 

# Time domain ‚Üí FFT ‚Üí Nh√¢n ‚Üí IFFT ‚Üí Filtered signal

# In[ ]:


def convolution_filter(signal_fft, kernel_fft):
    """
    Perform convolution in the frequency domain.
    signal_fft: array-like, FFT of the signal.
    kernel_fft: array-like, FFT of the kernel/filter.
    return: array-like, FFT of the filtered signal.
    """
    return signal_fft * kernel_fft

def filter_audio(input_file, output_file, cutoff_freq, sr, filter_type='low-pass'):
    """
    Filter an audio file using FFT and convolution, supporting both low-pass and high-pass filters.
    input_file: str - Path to the input audio file (.wav).
    output_file: str - Path to save the filtered audio file (.wav).
    cutoff_freq: float - Cutoff frequency for the filter (Hz).
    sr: int - Sampling rate of the audio file (Hz).
    filter_type: str - Type of filter ('low-pass', 'high-pass', or 'band-pass').
    """
    # Step 1: Load the audio file
    y_real, sr = sf.read(input_file)
    if len(y_real.shape) > 1:  # Convert to mono if stereo
        y_real = np.mean(y_real, axis=1)

    # Ensure signal length is sufficient for FFT
    n = len(y_real)
    fft_size = 2 ** int(np.ceil(np.log2(n + 1)))  # Ensure enough padding for convolution
    y_real = np.pad(y_real, (0, fft_size - n), mode='constant')

    # Step 2: Apply FFT to signal
    signal_fft = fft_from_scratch(y_real)

    # Step 3: Create kernel/filter in the frequency domain
    freqs = np.fft.fftfreq(fft_size, d=1/sr)
    kernel = np.zeros(fft_size, dtype=complex)
    if filter_type == 'low-pass':
        kernel[np.abs(freqs) <= cutoff_freq] = 1  # Low-pass filter
    elif filter_type == 'high-pass':
        kernel[np.abs(freqs) >= cutoff_freq] = 1  # High-pass filter
    elif filter_type == 'band-pass':
        bandwidth = 10  # Example bandwidth (adjustable)
        kernel[(np.abs(freqs) >= cutoff_freq - bandwidth) & (np.abs(freqs) <= cutoff_freq + bandwidth)] = 1
    else:
        raise ValueError("Invalid filter_type. Use 'low-pass', 'high-pass', or 'band-pass'.")

    kernel_fft = fft_from_scratch(kernel)

    # Step 4: Apply convolution in the frequency domain
    filtered_fft = convolution_filter(signal_fft, kernel_fft)

    # Step 5: Apply IFFT to get the filtered signal
    print("Performing IFFT...")
    filtered_signal = ifft_from_scratch(filtered_fft)

    # Step 6: Normalize the filtered signal
    filtered_signal = filtered_signal[:n]  # Remove padding
    filtered_signal = np.int16(filtered_signal / np.max(np.abs(filtered_signal)) * 32767)  # Normalize to 16-bit

    # Step 7: Save the filtered audio
    write(output_file, sr, filtered_signal)
    print(f"Filtered audio saved to {output_file}")

    # Return the filtered signal for playback
    return filtered_signal


# Ph·∫ßn n√†y n√≥ ch·∫°y b·ªã l·∫∑p √¢m thanh t ƒëang ki·∫øm l√Ω do t·∫°i sao

# In[39]:


# output_path = "mixed_convolution.wav"  # Output audio file path
# cutoff = 287  # Cutoff frequency in Hz
# filtered_audio = filter_audio(file_path, output_path, cutoff, frame_rate, filter_type='low-pass')


# # In[40]:


# # Play the filtered audio
# Audio(filtered_audio , rate=frame_rate)


# #### S·ª≠ d·ª•ng fftconvolve k·∫øt h·ª£p ng∆∞·ª°ng, Gaussian (s·ª≠ d·ª•ng th∆∞ vi·ªán)

# In[36]:


def filter_combined(input_file, output_file, freq_range, start_time, end_time, threshold=0.4, kernel_size=50, kernel_width=2.0, play_audio=False):
    """
    Apply threshold, Band-Stop Filter, and Gaussian smoothing to filter abnormal signal.

    Parameters:
        input_file (str): Path to the input audio file (.wav).
        output_file (str): Path to save the filtered audio file (.wav).
        freq_range (tuple): Frequency range to be filtered (low_freq, high_freq) in Hz.
        start_time (float): Start time of the range to apply the filter (in seconds).
        end_time (float): End time of the range to apply the filter (in seconds).
        threshold (float): Amplitude threshold to filter abnormal values.
        kernel_size (int): Size of the Gaussian kernel.
        kernel_width (float): Width of the Gaussian kernel.
        play_audio (bool): Whether to play the audio after filtering.
    """
    # Load audio file
    signal, sr = sf.read(input_file)
    if len(signal.shape) > 1:  # Convert to mono if stereo
        signal = np.mean(signal, axis=1)

    # Convert time range to sample range
    start_sample = int(start_time * sr)
    end_sample = int(end_time * sr)

    # Step 1: Apply threshold to specific time range
    segment = signal[start_sample:end_sample]
    segment[segment > threshold] = threshold  # Cap values above threshold
    segment[segment < -threshold] = -threshold  # Cap values below threshold

    # Step 2: Apply Band-Stop Filter to the thresholded segment
    low_freq, high_freq = freq_range
    nyquist = sr / 2  # Nyquist frequency
    low = low_freq / nyquist
    high = high_freq / nyquist
    b, a = butter(N=2, Wn=[low, high], btype='bandstop')  # Create Band-Stop Filter coefficients
    filtered_segment = filtfilt(b, a, segment)  # Apply Band-Stop Filter

    # Replace the original segment with the filtered segment
    signal[start_sample:end_sample] = filtered_segment

    # Step 3: Apply Gaussian smoothing to the entire signal
    kernel = np.exp(-np.linspace(-kernel_width, kernel_width, kernel_size)**2)
    kernel = kernel / np.sum(kernel)  # Normalize
    smoothed_signal = fftconvolve(signal, kernel, mode='same')  # Apply Gaussian smoothing

    # Normalize and save filtered audio
    smoothed_signal = smoothed_signal / np.max(np.abs(smoothed_signal))  # Normalize
    sf.write(output_file, smoothed_signal, sr)
    print(f"Filtered audio saved to {output_file}")

    # Plot signals for comparison
    plt.figure(figsize=(12, 8))
    plt.subplot(3, 1, 1)
    plt.plot(signal, label='Original Signal')
    plt.legend()
    plt.subplot(3, 1, 2)
    plt.plot(filtered_segment, label=f'Filtered Segment @ {freq_range} Hz with Threshold {threshold}', color='orange')
    plt.legend()
    plt.subplot(3, 1, 3)
    plt.plot(smoothed_signal, label='Smoothed Signal (Gaussian Kernel)', color='green')
    plt.legend()
    st.pyplot(plt.gcf())

    # Play audio if requested
    if play_audio:
        print("Playing filtered audio...")
        return Audio(data=smoothed_signal, rate=sr)



# In[37]:


output_path = "filtered_combined_signal.wav"

# Apply combined filter to remove frequency range (80 Hz to 90 Hz) with threshold
audio_player = filter_combined(
    input_file=file_path,
    output_file=output_path,
    freq_range=(92,278),  # Frequency range to remove
    start_time=22,        # Start time (seconds)
    end_time=23,          # End time (seconds)
    threshold= 1,        # Amplitude threshold
    kernel_size=50,       # Size of Gaussian kernel
    kernel_width=3.0,     # Width of Gaussian kernel
    play_audio=True
)

# Display audio player if returned
if audio_player:
    display(audio_player)


# ###  FFT l·ªçc theo magnitude threshold

# In[41]:


data_fft = np.fft.fft(signal_vector)
full_magnitudes = np.abs(data_fft)
max_magnitude = np.max(full_magnitudes)


# In[42]:


N_output = len(data_fft)  # T·ªïng s·ªë ƒëi·ªÉm trong ph·ªï FFT
delta_f = frame_rate / N_output   # ƒê·ªô ph√¢n gi·∫£i t·∫ßn s·ªë (b∆∞·ªõc nh·∫£y gi·ªØa c√°c bin)
num_positive_bins = (N_output + 1) // 2 # S·ªë l∆∞·ª£ng bin t·∫ßn s·ªë d∆∞∆°ng (bao g·ªìm DC)
frequencies = np.zeros(num_positive_bins, dtype=np.float64)
# T√≠nh to√°n t·∫ßn s·ªë d∆∞∆°ng
for k in range(num_positive_bins):
    frequencies[k] = k * delta_f
#---------------------------------------------------------------------------------#
magnitudes = np.abs(data_fft[:num_positive_bins]) # L·∫•y bi√™n ƒë·ªô th√¥ c·ªßa ph·∫ßn d∆∞∆°ng
# Chu·∫©n h√≥a ban ƒë·∫ßu: Chia cho t·ªïng s·ªë ƒëi·ªÉm FFT
magnitudes = magnitudes / N_output
# Nh√¢n ƒë√¥i c√°c th√†nh ph·∫ßn ƒë·ªÉ l·∫•y bi√™n ƒë·ªô v·∫≠t l√Ω (tr·ª´ DC v√† Nyquist)
if N_output % 2 == 0:
    magnitudes[1:-1] = magnitudes[1:-1] * 2
else:
    magnitudes[1:] = magnitudes[1:] * 2
threshold = 0.015
threshold_value = threshold * max_magnitude
filtered = np.where(np.abs(data_fft) > threshold_value, data_fft, 0)
#---------------------------------------------------------------------------------#
filtered_magnitudes = np.abs(filtered[:num_positive_bins])
# Chu·∫©n h√≥a ban ƒë·∫ßu: Chia cho t·ªïng s·ªë ƒëi·ªÉm FFT
filtered_magnitudes = filtered_magnitudes / N_output
# Nh√¢n ƒë√¥i c√°c th√†nh ph·∫ßn ƒë·ªÉ l·∫•y bi√™n ƒë·ªô v·∫≠t l√Ω (tr·ª´ DC v√† Nyquist)
if N_output % 2 == 0:
    filtered_magnitudes[1:-1] = filtered_magnitudes[1:-1] * 2
else:
    filtered_magnitudes[1:] = filtered_magnitudes[1:] * 2
#---------------------------------------------------------------------------------#
plt.figure(figsize=(14.5, 6))
# V·∫Ω ph·ªï t·∫ßn s·ªë g·ªëc v·ªõi m√†u xanh lam
plt.plot(frequencies, magnitudes,
        label='Ph·ªï G·ªëc', color='#1f77b4', linewidth=1)
# V·∫Ω ph·ªï t·∫ßn s·ªë ƒë√£ l√†m s·∫°ch v·ªõi m√†u cam, ƒë√® l√™n ph·ªï g·ªëc
plt.plot(frequencies, filtered_magnitudes,
        label='Ph·ªï ƒê√£ L√†m S·∫°ch', color='#ff7f0e', linewidth=1)
plt.title(f'Ph·ªï T·∫ßn S·ªë c·ªßa T√≠n hi·ªáu √Çm thanh (G·ªëc v√† ƒê√£ L√†m S·∫°ch)')
plt.xlabel('T·∫ßn s·ªë (Hz)')
plt.ylabel('Bi√™n ƒë·ªô')
plt.grid(True)
plt.xlim(0, frame_rate / 2)
plt.legend()
st.pyplot(plt.gcf())


# In[43]:


signal_fft_inverse = np.real(np.fft.ifft(filtered)).astype(np.float64)


# **Nghe l·∫°i t√≠n hi·ªáu ƒë√£ l·ªçc**

# In[44]:


# T·∫°o ƒë·ªëi t∆∞·ª£ng AudioSegment.
audio_segment = AudioSegment(
    signal_fft_inverse.astype(np.int16).tobytes(),
    frame_rate=frame_rate,
    sample_width=sample_width,
    channels=channels
)
audio_segment += 2
display(audio_segment)
#---------------------------------------------------------------------------------#
time_axis_original = np.arange(len(signal_vector)) / frame_rate
time_axis_cleaned = np.arange(len(signal_fft_inverse)) / frame_rate

plt.figure(figsize=(12, 6))
# V·∫Ω t√≠n hi·ªáu g·ªëc v·ªõi m√†u xanh lam
plt.plot(time_axis_original, signal_vector,
            label='T√≠n hi·ªáu G·ªëc', color='#1f77b4', linewidth=1)
# V·∫Ω t√≠n hi·ªáu ƒë√£ l√†m s·∫°ch v·ªõi m√†u cam
plt.plot(time_axis_cleaned, signal_fft_inverse,
            label='T√≠n hi·ªáu ƒê√£ L√†m S·∫°ch', color='#ff7f0e', linewidth=1)
plt.title('T√≠n hi·ªáu √Çm thanh trong Mi·ªÅn Th·ªùi gian (G·ªëc v√† ƒê√£ L√†m S·∫°ch)')
plt.xlabel('Th·ªùi gian (gi√¢y)')
plt.ylabel('Bi√™n ƒë·ªô')
plt.grid(True)
plt.legend()
plt.legend(loc='upper left')
plt.tight_layout()
st.pyplot(plt.gcf())


# #### Kh·ª≠ nhi·ªÖu b·∫±ng ph∆∞∆°ng ph√°p tr·ª´ ph·ªï (SPECTRAL SUBTRACTION)

# In[ ]:





# #### Kh·ª≠ nhi·ªÖu b·∫±ng ng∆∞·ª°ng m·∫≠t ƒë·ªô ph·ªï c√¥ng su·∫•t (PSD THRESHOLDING) tr·ª±c ti·∫øp

# In[ ]:





# #### ANN 

# In[ ]:


# def relu(Z):
#     return np.maximum(0, Z)

# def relu_derivative(Z):
#     return Z > 0

# def forward_prop(W1, W2, X):
#     Z1 = np.dot(W1, X)
#     A1 = relu(Z1)
#     Z2 = np.dot(W2, A1)
#     A2 = Z2
#     return Z1, A1, Z2, A2

# def back_prop(m, W1, W2, Z1, A1, Z2, A2, Y):
#     dZ2 = (A2 - Y)
#     dW2 = np.dot(dZ2, A1.T) / m
#     dA1 = np.dot(W2.T, dZ2)
#     dZ1 = dA1 * relu_derivative(Z1)
#     dW1 = np.dot(dZ1, X.T) / m
#     return dZ2, dW2, dZ1, dW1

# N = 32
# batch = 10000
# lr = 0.01
# iterations = 10000

# sig = np.random.randn(batch, N) + 1j*np.random.randn(batch, N)
# F = np.fft.fft(sig, axis=-1)
# X = np.hstack([sig.real, sig.imag]).T
# Y = np.hstack([F.real, F.imag]).T
# n_input = X.shape[0]
# n_output = Y.shape[0]
# n_hidden = 128


# np.random.seed(42)
# W1 = np.random.randn(n_hidden, n_input) * 0.01
# W2 = np.random.randn(n_output, n_hidden) * 0.01

# losses = []
# m = X.shape[1]
# for i in range(iterations):
#     Z1, A1, Z2, A2 = forward_prop(W1, W2, X)
#     loss = np.mean((A2 - Y) ** 2)
#     losses.append(loss)
#     dZ2, dW2, dZ1, dW1 = back_prop(m, W1, W2, Z1, A1, Z2, A2, Y)
#     W2 -= lr * dW2
#     W1 -= lr * dW1
#     if i % 1000 == 0:
#         print(f"Iteration {i}: Loss = {loss:.6f}")

# plt.plot(losses)
# plt.xlabel("Epochs")
# plt.ylabel("Loss (MSE)")
# plt.yscale('log')
# plt.title("Training Loss (DFT Approximation)")
# st.pyplot(plt.gcf())


# ##  Conclusion

# In[ ]:





# References:
# 
# [1] Meyer C.D, Matrix analysis and Applied linear algebra, SIAM, 2000, chapter 5, section 8
# 
# [2] Isaac Amidror, Mastering the Discrete Fourier Transform in One, Two or Several Dimensions: Pitfalls and Artifacts, Springer,2013
